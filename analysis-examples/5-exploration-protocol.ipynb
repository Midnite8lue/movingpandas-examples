{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A protocol for movement data exploration\n",
    "\n",
    "This notebook presents a systematic movement data exploration protocol. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIGSIZE = (600,400)\n",
    "SMSIZE = 300\n",
    "COLOR = 'darkblue'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import movingpandas as mpd\n",
    "import datashader as ds\n",
    "import holoviews as hv\n",
    "\n",
    "from shapely.geometry import Point, LineString\n",
    "from holoviews.operation.datashader import datashade, spread\n",
    "from holoviews.element import tiles\n",
    "from holoviews import opts, dim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_files = [\n",
    "    'E:/Geodata/AISDK/raw_ais/aisdk_20170701.csv',\n",
    "    #'E:/Geodata/AISDK/raw_ais/aisdk_20170702.csv',\n",
    "    #'E:/Geodata/AISDK/raw_ais/aisdk_20170703.csv',\n",
    "    #'E:/Geodata/AISDK/raw_ais/aisdk_20170704.csv',\n",
    "    #'E:/Geodata/AISDK/raw_ais/aisdk_20170705.csv',\n",
    "    #'E:/Geodata/AISDK/raw_ais/aisdk_20170706.csv',\n",
    "    'E:/Geodata/AISDK/raw_ais/aisdk_20180101.csv',\n",
    "    #'E:/Geodata/AISDK/raw_ais/aisdk_20180102.csv',\n",
    "    #'E:/Geodata/AISDK/raw_ais/aisdk_20180103.csv',\n",
    "    #'E:/Geodata/AISDK/raw_ais/aisdk_20180104.csv',\n",
    "    #'E:/Geodata/AISDK/raw_ais/aisdk_20180105.csv',\n",
    "    #'E:/Geodata/AISDK/raw_ais/aisdk_20180106.csv'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(input_files[0], nrows=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SOG'].hist(bins=100, figsize=(15,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = None\n",
    "for input_file in input_files[:2]: \n",
    "    a = pd.read_csv(input_file, usecols=['# Timestamp', 'MMSI', 'Latitude', 'Longitude', 'SOG', 'Type of mobile', 'Ship type', 'Navigational status'])\n",
    "    a = a[(a['Type of mobile'] == 'Class A') & (a.SOG>0)]\n",
    "    a.drop(columns=['Type of mobile', 'SOG'], inplace=True)\n",
    "    if df is None:\n",
    "        df = a\n",
    "    else:\n",
    "        df = df.append(a)\n",
    "    \n",
    "df.rename(columns={'# Timestamp':'time', 'MMSI':'id', 'Latitude':'lat', 'Longitude':'lon', 'Ship type':'shiptype', 'Navigational status':'navstat'}, inplace=True)\n",
    "df['time'] = pd.to_datetime(df['time'], format='%d/%m/%Y %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, 'x'], df.loc[:, 'y'] = ds.utils.lnglat_to_meters(df.lon, df.lat)\n",
    "\n",
    "df.set_index('time', inplace=True)\n",
    "\n",
    "df['navstat'] = df['navstat'].astype('category')\n",
    "df['shiptype'] = df['shiptype'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of records: {} million'.format(round(len(df)/1000000)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A) Missing data\n",
    "\n",
    "Checking for missing data is a common starting point for exploring new movement datasets. At this early stage, we usually start with raw location records that have yet to be aggregated into trajectories. Therefore, initial analyses look at elementary position records.\n",
    "\n",
    "The following protocol steps target issues of missing data with respect to movement data's spatial, temporal, and attribute dimensions.\n",
    "\n",
    "\n",
    "### A-1) Spatial gaps & outliers\n",
    "\n",
    "To gain an overview, the analysis should start from the whole time span before drilling down. Spatial context (usually in the form of base maps) is essential when assessing spatial extent and gaps because context influences movement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spatial spread / extent & outliers (whole territory / all movers / whole time span)\n",
    "\n",
    "This step addresses the question if the dataset covers the expected spatial extent. This can be as simple as checking the minimum and maximum coordinate values of the raw records. However, it is not uncommon to encounter spurious location records or outliers that are not representative of the actual covered extent. These outliers may be truly erroneous positions but can also be correct positions that happen to be located outside the usual extent. Looking at elementary position records only, it is usually not possible to distinguish these two cases. It is therefore necessary to take note of these outliers and investigate further in later steps.\n",
    "\n",
    "TODO: consequences \n",
    "\n",
    "Classic scatter plots (or point maps) are helpful at this step. Point density maps (often called heat maps) on their default settings tend to hide outliers and are therefore not recommended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Spatial extent: x_min={df.lon.min()}, x_max={df.lon.max()}, y_min={df.lat.min()}, y_max={df.lat.max()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_basic_scatter(df, color='darkblue', title='', width=FIGSIZE[0], height=FIGSIZE[1], size=2):\n",
    "    opts.defaults(opts.Overlay(active_tools=['wheel_zoom']))\n",
    "    pts = df.hvplot.scatter(x='x', y='y', datashade=True, cmap=[color, color], frame_width=width, frame_height=height, title=str(title))\n",
    "    return tiles.OSM() * spread(pts, px=size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_basic_scatter(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df.lon>-90) & (df.lon<90) & (df.lat>0) & (df.lat<80)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_df = df[(df.lon>0) & (df.lon<20) & (df.lat>52) & (df.lat<60)]\n",
    "cropped_df['navstat'] = cropped_df['navstat'].astype('category')\n",
    "cropped_df['shiptype'] = cropped_df['shiptype'].astype('category')\n",
    "plot_basic_scatter(cropped_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spatial gaps (selected areas / all movers / whole time span)\n",
    "\n",
    "This step addresses the question if there are spatial gaps in the data coverage. Depending on the type of movers, gaps in certain spatial contexts are to be expected. For example, we wouldn't expect taxi locations in lakes. Other gaps may indicate issues with the data collection process or the data export used to generate the analysis dataset. Therefore, it is essential to evaluate these gaps in their spatial context using base maps showing relevant geographic features, such as the road network for vehicle data or navigation markers for vessel data. The visualization scale influences which size of gaps can be discovered. However, there are of course practical limitations to exploring ever more detailed scales and resulting continuously growing numbers of gaps.\n",
    "\n",
    "TODO: consequences\n",
    "\n",
    "Point density maps are helpful since they make it easy to identify areas with low densities, ignoring occasional outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_point_density(df, title='', width=FIGSIZE[0], height=FIGSIZE[1]):\n",
    "    opts.defaults(opts.Overlay(active_tools=['wheel_zoom']))\n",
    "    pts = df.hvplot.scatter(x='x', y='y', title=str(title), datashade=True, frame_width=width, frame_height=height)\n",
    "    return tiles.OSM() * pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_point_density(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A-2) Temporal gaps & outliers\n",
    "\n",
    "#### Temporal extent & outliers (whole territory / all movers / whole time span)\n",
    "\n",
    "This step addresses the question if the dataset covers the expected temporal extent. Similar to exploring the spatial extent, the obvious step is to determine the minimum and maximum timestamps first. Since GPS tracking requires accurate clocks to function, time information on the tracker is usually reliable. However, it is not guaranteed that these timestamps make it through the whole data collection and (pre)processing chain leading up to the exploratory analysis. For example, in some cases, tracker (or sender) time is replaced by receiver or storage time. Thus clock errors on the receiving or storage devices can result in unexpected timestamps.\n",
    "\n",
    "TODO: consequences\n",
    "\n",
    "Temporal charts, particularly record counts over time, are helpful to gain a first impression of the overall temporal extent and whether it is continuous or split into multiple time frames with little or no data in between."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Temporal extent: {df.index.min()} to {df.index.max()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_SAMPLE = '15min'\n",
    "\n",
    "df['id'].resample(TIME_SAMPLE).count()\\\n",
    "    .hvplot(title=f'Number of records per {TIME_SAMPLE}', width=FIGSIZE[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Temporal gaps in linear sequence & temporal cycles (whole territory / all movers / time spans)\n",
    "\n",
    "This step addresses the question if there are temporal gaps in the dataset. Temporal gaps can be due to scheduled breaks in data collection, deliberate choices during data export, as well as unintended issues during data collection or (pre)processing. Similar to exploring spatial gaps, the temporal scale influences which size of gaps can be discovered. Temporal gaps can be one-time events or exhibit reoccurring patterns. For example, daily and weekly cycles are typical for human movement data.\n",
    "\n",
    "TODO: consequences\n",
    "\n",
    "Two-dimensional time histograms are helpful at this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_df = df['id'].groupby([df.index.hour, pd.Grouper(freq='d')]).count().to_frame(name='n')\n",
    "counts_df.rename_axis(['hour', 'day'], inplace=True)\n",
    "counts_df.hvplot.heatmap(title='Record count', x='hour', y='day', C='n', width=FIGSIZE[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A-3) Spatiotemporal changes / gaps\n",
    "\n",
    "While the previous two steps looked at spatial gaps over the whole time span or temporal gaps for the whole territory, this step aims to explore spatiotemporal changes and gaps.\n",
    "\n",
    "#### Changing extent\n",
    "\n",
    "This step addresses the question whether there are changes in spatial extent over time. Changing spatial extent may be due to planned extensions or reductions of the data collection / observation area. Similarly, the extent is also expected to shift if the movers collectively change their location, as is the case, for example, with tracks of migrating birds.\n",
    "\n",
    "TODO: consequences\n",
    "\n",
    "Small multiples are helpful since they provide a quick way to compare extents during different time spans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_multiple_by_day(df, day):\n",
    "    return plot_basic_scatter(df[df.index.date==day], title=day, width=SMSIZE, height=SMSIZE)\n",
    "    \n",
    "def plot_multiples_by_day(df):\n",
    "    days = df.index.to_period('D').unique()\n",
    "    a = None\n",
    "    for a_day in days:\n",
    "        a_day = a_day.to_timestamp().date()\n",
    "        plot = plot_multiple_by_day(df, a_day)\n",
    "        if a is None: a = plot\n",
    "        else: a = a  + plot\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_multiples_by_day(df).cols(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_multiples_by_day(cropped_df).cols(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_multiple_by_hour_of_day(df, hour, fun):\n",
    "    return fun(df[df.index.hour==hour], title=hour, width=SMSIZE, height=SMSIZE)\n",
    "    \n",
    "def plot_multiples_by_hour_of_day(df, hours=range(0,24), fun=plot_basic_scatter):\n",
    "    a = None\n",
    "    for hour in hours:\n",
    "        plot = plot_multiple_by_hour_of_day(df, hour, fun)\n",
    "        if a is None: a = plot\n",
    "        else: a = a + plot\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plot_multiples_by_hour_of_day(df[df.shiptype=='Fishing']).cols(2)\n",
    "plot_multiples_by_hour_of_day(df, hours=[6,7,8,9]).cols(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Temporary gaps\n",
    "\n",
    "This step addresses the question whether there are temporary gaps in the overall spatial coverage. Like temporary changes in the overall extent, temporary gaps can be due to mover behavior, as well as planned and unplanned changes of the data collection or (pre)processing workflows.\n",
    "\n",
    "TODO: consequences\n",
    "\n",
    "Small multiples of density maps or animated density maps are helpful at this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_multiples_by_hour_of_day(cropped_df, hours=[6,7,8,9], fun=plot_point_density).cols(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A-4) Attribute gaps\n",
    "\n",
    "Some attributes may only be available during certain time spans / or in certain areas.\n",
    "\n",
    "#### Spatial attribute gaps\n",
    "\n",
    "This step addresses the question if there are areas with missing attribute data. Locally missing attribute data can be due to heterogeneous data collection system setups.\n",
    "\n",
    "TODO: consequences\n",
    "\n",
    "The methods used to explore spatial extent and gaps can be adopted to missing attribute data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORY = 'shiptype' #'navstat'\n",
    "COLOR_HIGHLIGHT = 'red'\n",
    "COLOR_BASE = 'grey'\n",
    "\n",
    "cats = df[CATEGORY].unique()\n",
    "#[cat for cat in cats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = {} \n",
    "for cat in cats:\n",
    "    cmap[cat] = COLOR_BASE\n",
    "cmap['Unknown value'] = COLOR_HIGHLIGHT\n",
    "cmap['Undefined'] = COLOR_HIGHLIGHT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_categorized_scatter(df, cat, title='', width=SMSIZE, height=SMSIZE, cmap=cmap):\n",
    "    opts.defaults(opts.Overlay(active_tools=['wheel_zoom']))\n",
    "    pts = df.hvplot.scatter(x='x', y='y', datashade=True, by=cat, colormap=cmap, legend=True, frame_width=width, frame_height=height, title=str(title))\n",
    "    return tiles.OSM() * pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tmp = df\n",
    "unknown = tmp[(tmp[CATEGORY]=='Unknown value') | (tmp[CATEGORY]=='Undefined')]\n",
    "known = tmp[(tmp[CATEGORY]!='Unknown value') & (tmp[CATEGORY]!='Undefined')]\n",
    "\n",
    "( plot_categorized_scatter(tmp, CATEGORY, title='Categorized', width=SMSIZE, height=SMSIZE, cmap=cmap) + \n",
    "  plot_basic_scatter(unknown, COLOR_HIGHLIGHT, title='Unknown only', width=SMSIZE, height=SMSIZE, size=1) +\n",
    "  plot_basic_scatter(known, COLOR_BASE, title='Known only', width=SMSIZE, height=SMSIZE, size=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Temporal attribute gaps\n",
    "\n",
    "This step addresses the question if there are temporary gaps in attribute data. Changes to the data collection or (pre)processing workflow can affect which attributes are available during certain time spans.\n",
    "\n",
    "TODO: consequences\n",
    "\n",
    "The methods used to explore temporal extent and gaps can be adopted to missing attribute data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_multiples_by_day(unknown).cols(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A-5) Gaps in trajectories\n",
    "\n",
    "Depending on the method used for splitting tracks into trajectories, the resulting trajectories can include gaps. These gaps can be due to technical failure of the tracking device, the mover leaving the observable area, deliberate deactivation of the tracking device, or (pre)processing issues. \n",
    "\n",
    "TODO: consequences\n",
    "\n",
    "TODO: method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sin, cos, atan2, radians, degrees, sqrt, pi\n",
    "\n",
    "R_EARTH = 6371000  # radius of earth in meters\n",
    "C_EARTH = 2 * R_EARTH * pi  # circumference\n",
    "\n",
    "def compute_distance(row):\n",
    "    lon1 = row['prev_lon']\n",
    "    lat1 = row['prev_lat']\n",
    "    lon2 = row['lon']\n",
    "    lat2 = row['lat']\n",
    "    delta_lat = radians(lat2 - lat1)\n",
    "    delta_lon = radians(lon2 - lon1)\n",
    "    a = sin(delta_lat/2) * sin(delta_lat/2) + cos(radians(lat1)) * cos(radians(lat2)) * sin(delta_lon/2) * sin(delta_lon/2)\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "    dist = R_EARTH * c\n",
    "    return dist\n",
    "\n",
    "def connect_pts(row):\n",
    "    lon1 = row['prev_lon']\n",
    "    lat1 = row['prev_lat']\n",
    "    lon2 = row['lon']\n",
    "    lat2 = row['lat']\n",
    "    return LineString([(lon1, lat1), (lon2, lat2)])\n",
    "\n",
    "def find_gaps(df, min_dist, max_dist):\n",
    "    if len(df)<2:\n",
    "        return None\n",
    "    i = df.copy()\n",
    "    i = i.assign(prev_lon=i.lon.shift())\n",
    "    i = i.assign(prev_lat=i.lat.shift())\n",
    "    i = i.assign(dist=i.apply(compute_distance, axis=1))\n",
    "    i = i[(i.dist>min_dist) & (i.dist<max_dist)]\n",
    "    if len(i)==0: \n",
    "        return None\n",
    "    i = i.assign(geometry=i.apply(connect_pts, axis=1))\n",
    "    return i\n",
    "\n",
    "def make_gap_gdf(df, min_dist, max_dist):\n",
    "    a = None\n",
    "    for the_id in df.id.unique():\n",
    "        i = df[df.id==the_id]\n",
    "        gaps_df = find_gaps(i, min_dist, max_dist)\n",
    "        if gaps_df is None:\n",
    "            continue\n",
    "        if a is None: \n",
    "            a = gaps_df\n",
    "        else:\n",
    "            a = a.append(gaps_df)\n",
    "    if a is not None:\n",
    "        return gpd.GeoDataFrame(a, geometry='geometry')\n",
    "\n",
    "def plot_gaps(df, min_dist, max_dist, width=FIGSIZE[0], height=FIGSIZE[1]):\n",
    "    gaps_gdf = make_gap_gdf(df, min_dist, max_dist)\n",
    "    if gaps_gdf is not None:\n",
    "        plot = gaps_gdf.hvplot(geo=True, color=COLOR_HIGHLIGHT, frame_width=width, frame_height=height)\n",
    "        return tiles.OSM() * plot   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gaps(cropped_df, min_dist=10000, max_dist=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix -- Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = df[(df['id']==304752000) | (df['id']==257024000)]\n",
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, df in sample_df.groupby('id'):\n",
    "    print(f'{name}: {len(df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "grouped = [df[['id','x','y']] for name, df in sample_df.groupby(['id', pd.Grouper(freq='d')])]\n",
    "path = hv.Path(grouped, kdims=['x','y'], vdims=['id','x']).opts(line_width=2, width=600, color=COLOR)\n",
    "plot = datashade(path).opts(frame_height=FIGSIZE[1], frame_width=FIGSIZE[0])\n",
    "tiles.OSM() * plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = [df[['x','y']] for name, df in cropped_df.groupby(['id', pd.Grouper(freq='d')]) if len(df)>100]\n",
    "path = hv.Path(grouped, kdims=['x','y'])\n",
    "plot = datashade(path).opts(frame_height=FIGSIZE[1], frame_width=FIGSIZE[0])\n",
    "tiles.OSM() * plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = cropped_df\n",
    "\n",
    "a = None\n",
    "for the_id in tmp.id.unique():\n",
    "    i = tmp[tmp.id==the_id].copy()\n",
    "    i = i.assign(prev_lon=i.lon.shift())\n",
    "    i = i.assign(prev_lat=i.lat.shift())\n",
    "    i = i.assign(dist=i.apply(compute_distance, axis=1))    \n",
    "    #i = find_gaps(i, 1000, 10000000)\n",
    "    plot = hv.Path(i, kdims=['x','y'], vdims=['id', 'dist']).opts(color='dist', line_width=4)\n",
    "    plot = datashade(plot, normalization='linear', aggregator=ds.by('id', ds.min(\"dist\")))\n",
    "    #plot = datashade(plot, normalization='linear')\n",
    "    if a is None: a = plot\n",
    "    else: a = a * plot\n",
    "tiles.OSM() * a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a * sample_df.hvplot.scatter(x='x', y='y', datashade=True, by='id', frame_width=FIGSIZE[0], frame_height=FIGSIZE[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datashade(hv.Path(sample_df, kdims=['x','y']), normalization='linear', aggregator=ds.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = sample_df[['id','x','y']]\n",
    "hv.Path(tmp[tmp.id==304752000], kdims=['x','y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
